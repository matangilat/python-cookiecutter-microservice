services:
  {% if cookiecutter.database_type == 'postgresql' %}
  postgres:
    image: postgres:15-alpine
    environment:
      POSTGRES_DB: {{ cookiecutter.project_slug }}
      POSTGRES_USER: admin
      POSTGRES_PASSWORD: changeme
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U admin -d {{ cookiecutter.project_slug }}"]
      interval: 10s
      timeout: 5s
      retries: 5
  {% elif cookiecutter.database_type == 'mysql' %}
  mysql:
    image: mysql:8.0
    environment:
      MYSQL_DATABASE: {{ cookiecutter.project_slug }}
      MYSQL_USER: admin
      MYSQL_PASSWORD: changeme
      MYSQL_ROOT_PASSWORD: rootpass
    ports:
      - "3306:3306"
    volumes:
      - mysql_data:/var/lib/mysql
    healthcheck:
      test: ["CMD", "mysqladmin", "ping", "-h", "localhost"]
      interval: 10s
      timeout: 5s
      retries: 5
  {% elif cookiecutter.database_type == 'mongodb' %}
  mongodb:
    image: mongo:7
    environment:
      MONGO_INITDB_DATABASE: {{ cookiecutter.project_slug }}
      MONGO_INITDB_ROOT_USERNAME: admin
      MONGO_INITDB_ROOT_PASSWORD: changeme
    ports:
      - "27017:27017"
    volumes:
      - mongodb_data:/data/db
    healthcheck:
      test: ["CMD", "mongosh", "--eval", "db.adminCommand('ping')"]
      interval: 10s
      timeout: 5s
      retries: 5
  {% endif %}

  {% if cookiecutter.cache_type == 'redis' %}
  redis:
    image: redis:7-alpine
    command: redis-server --appendonly yes
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
  {% elif cookiecutter.cache_type == 'memcached' %}
  memcached:
    image: memcached:1.6-alpine
    ports:
      - "11211:11211"
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "11211"]
      interval: 10s
      timeout: 5s
      retries: 5
  {% endif %}

  {% if cookiecutter.queue_type == 'kafka' %}
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2181:2181"
    volumes:
      - zookeeper_data:/var/lib/zookeeper

  kafka:
    image: confluentinc/cp-kafka:7.5.0
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
    ports:
      - "9092:9092"
      - "29092:29092"
    volumes:
      - kafka_data:/var/lib/kafka
    healthcheck:
      test: ["CMD", "kafka-broker-api-versions", "--bootstrap-server", "localhost:9092"]
      interval: 10s
      timeout: 10s
      retries: 5
  {% elif cookiecutter.queue_type == 'rabbitmq' %}
  rabbitmq:
    image: rabbitmq:3.12-management-alpine
    environment:
      RABBITMQ_DEFAULT_USER: admin
      RABBITMQ_DEFAULT_PASS: changeme
    ports:
      - "5672:5672"
      - "15672:15672"
    volumes:
      - rabbitmq_data:/var/lib/rabbitmq
    healthcheck:
      test: ["CMD", "rabbitmq-diagnostics", "-q", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
  {% endif %}

  {% if cookiecutter.deploy_monitoring_stack == 'yes' %}
  prometheus:
    image: prom/prometheus:v2.48.0
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:9090/-/healthy"]
      interval: 10s
      timeout: 5s
      retries: 5

  grafana:
    image: grafana/grafana:10.2.0
    environment:
      GF_SECURITY_ADMIN_PASSWORD: admin
    ports:
      - "3000:3000"
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana-datasources.yaml:/etc/grafana/provisioning/datasources/datasources.yaml
      - ./monitoring/grafana-dashboards.yaml:/etc/grafana/provisioning/dashboards/dashboards.yaml
      - ./monitoring/node-exporter-dashboard.json:/var/lib/grafana/dashboards/node-exporter.json
      - ./monitoring/node-exporter-full-dashboard.json:/var/lib/grafana/dashboards/node-exporter-full.json
    depends_on:
      - prometheus
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:3000/api/health"]
      interval: 10s
      timeout: 5s
      retries: 5
  {% endif %}

  {% if cookiecutter.enable_node_exporter == 'yes' %}
  node-exporter:
    image: prom/node-exporter:v1.7.0
    command:
      - '--path.procfs=/host/proc'
      - '--path.sysfs=/host/sys'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
    ports:
      - "9100:9100"
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:9100/metrics"]
      interval: 10s
      timeout: 5s
      retries: 5
  {% endif %}

  api:
    build: .
    {% if cookiecutter.web_framework == 'fastapi' %}
    command: python3 -m src.app_fastapi
    {% else %}
    command: python3 -m src.app_flask
    {% endif %}
    ports:
      - "8000:8000"
    environment:
      - DEBUG=true
      - LOG_LEVEL=DEBUG
      {% if cookiecutter.database_type == 'postgresql' %}
      - DB_HOST=postgres
      {% elif cookiecutter.database_type == 'mysql' %}
      - DB_HOST=mysql
      {% elif cookiecutter.database_type == 'mongodb' %}
      - DB_HOST=mongodb
      {% endif %}
      {% if cookiecutter.cache_type == 'redis' %}
      - CACHE_HOST=redis
      {% elif cookiecutter.cache_type == 'memcached' %}
      - CACHE_HOST=memcached
      {% endif %}
      {% if cookiecutter.queue_type == 'kafka' %}
      - QUEUE_HOST=kafka
      {% elif cookiecutter.queue_type == 'rabbitmq' %}
      - QUEUE_HOST=rabbitmq
      {% endif %}
    depends_on:
      {% if cookiecutter.database_type == 'postgresql' %}
      - postgres
      {% elif cookiecutter.database_type == 'mysql' %}
      - mysql
      {% elif cookiecutter.database_type == 'mongodb' %}
      - mongodb
      {% endif %}
      {% if cookiecutter.cache_type == 'redis' %}
      - redis
      {% elif cookiecutter.cache_type == 'memcached' %}
      - memcached
      {% endif %}
      {% if cookiecutter.queue_type == 'kafka' %}
      - kafka
      {% elif cookiecutter.queue_type == 'rabbitmq' %}
      - rabbitmq
      {% endif %}
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/healthz"]
      interval: 10s
      timeout: 5s
      retries: 5

    # Alternative (commented): use the async health-check CLI that performs
    # database/cache/queue checks. To use this, ensure the image installs the
    # optional dependencies (see requirements-health.txt) and that the CLI path
    # exists in the container.
    # healthcheck:
    #   test: ["CMD-SHELL", "python -m src.utils.health_check_cli --timeout 5 --json"]
    #   interval: 30s
    #   timeout: 10s
    #   retries: 3
    #   start_period: 30s

  {% if cookiecutter.use_async_workers == 'yes' and cookiecutter.queue_type != 'none' %}
  worker:
    build: .
    command: python3 -m src.worker
    environment:
      - DEBUG=true
      - LOG_LEVEL=DEBUG
      {% if cookiecutter.database_type == 'postgresql' %}
      - DB_HOST=postgres
      {% elif cookiecutter.database_type == 'mysql' %}
      - DB_HOST=mysql
      {% elif cookiecutter.database_type == 'mongodb' %}
      - DB_HOST=mongodb
      {% endif %}
      {% if cookiecutter.cache_type == 'redis' %}
      - CACHE_HOST=redis
      {% elif cookiecutter.cache_type == 'memcached' %}
      - CACHE_HOST=memcached
      {% endif %}
      {% if cookiecutter.queue_type == 'kafka' %}
      - QUEUE_HOST=kafka
      {% elif cookiecutter.queue_type == 'rabbitmq' %}
      - QUEUE_HOST=rabbitmq
      {% endif %}
    depends_on:
      {% if cookiecutter.database_type == 'postgresql' %}
      - postgres
      {% elif cookiecutter.database_type == 'mysql' %}
      - mysql
      {% elif cookiecutter.database_type == 'mongodb' %}
      - mongodb
      {% endif %}
      {% if cookiecutter.queue_type == 'kafka' %}
      - kafka
      {% elif cookiecutter.queue_type == 'rabbitmq' %}
      - rabbitmq
      {% endif %}
  {% endif %}

volumes:
  {% if cookiecutter.database_type == 'postgresql' %}
  postgres_data:
  {% elif cookiecutter.database_type == 'mysql' %}
  mysql_data:
  {% elif cookiecutter.database_type == 'mongodb' %}
  mongodb_data:
  {% endif %}
  {% if cookiecutter.cache_type == 'redis' %}
  redis_data:
  {% endif %}
  {% if cookiecutter.queue_type == 'kafka' %}
  zookeeper_data:
  kafka_data:
  {% elif cookiecutter.queue_type == 'rabbitmq' %}
  rabbitmq_data:
  {% endif %}
  {% if cookiecutter.deploy_monitoring_stack == 'yes' %}
  prometheus_data:
  grafana_data:
  {% endif %}
